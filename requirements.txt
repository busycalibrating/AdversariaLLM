accelerate
flash-attn @ https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.2/flash_attn-2.8.2+cu12torch2.7cxx11abiTRUE-cp310-cp310-linux_x86_64.whl
hydra-core>=1.3.0
hydra-submitit-launcher
jailbreakbench @ git+https://github.com/busycalibrating/jailbreakbench@main
json5>=0.12.0
judgezoo
lm-format-enforcer>=0.10.11
matplotlib
omegaconf>=2.1.0
openai>=1.79.0
orjson
peft
pytest
scikit-learn
seaborn
submitit
torch==2.7.0
tqdm>=4.66.5
transformers>=4.56.0
beartype
pymongo