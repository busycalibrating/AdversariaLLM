2024-12-17 15:02:06,729 INFO    StreamThr :1644618 [internal.py:wandb_internal():85] W&B internal server running at pid: 1644618, started at: 2024-12-17 15:02:06.728060
2024-12-17 15:02:06,730 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: status
2024-12-17 15:02:06,738 INFO    WriterThread:1644618 [datastore.py:open_for_write():87] open: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/run-2024-12-17-14-45-07.wandb
2024-12-17 15:02:06,739 DEBUG   SenderThread:1644618 [sender.py:send():379] send: header
2024-12-17 15:02:06,757 DEBUG   SenderThread:1644618 [sender.py:send():379] send: run
2024-12-17 15:02:06,759 INFO    SenderThread:1644618 [sender.py:_setup_resume():749] checking resume status for omega_alignment/vlm_icml_leo/2024-12-17-14-45-07
2024-12-17 15:02:07,058 INFO    SenderThread:1644618 [sender.py:_setup_resume():829] configured resuming with: ResumeState(resumed=True,step=606,history=606,events=0,output=710,runtime=201.596975,wandb_runtime=None,summary={'_runtime': 200.21257710456848, '_step': 605, '_timestamp': 1734443315.9482632, '_wandb.runtime': 200, 'eval/harmless_loss': 0.02500000037252903, 'eval/harmless_model_preparation_time': 0.0036, 'eval/harmless_runtime': 8.1344, 'eval/harmless_samples_per_second': 4.917, 'eval/harmless_steps_per_second': 0.615, 'total_flos': 0, 'train/attack_loss': 0, 'train/away_loss': -5.010383129119873, 'train/epoch': 1, 'train/global_step': 75, 'train/grad_norm': 2.0800185203552246, 'train/learning_rate': 7.885298685522235e-07, 'train/loss': -1.501, 'train/pretrain_eval_harmless_loss': 0.05000000074505806, 'train/pretrain_eval_harmless_model_preparation_time': 0.0036, 'train/pretrain_eval_harmless_runtime': 8.7425, 'train/pretrain_eval_harmless_samples_per_second': 4.575, 'train/pretrain_eval_harmless_steps_per_second': 0.572, 'train/retain_loss': 0.9815905690193176, 'train/toward_loss': 0.050000254064798355, 'train_loss': -1.1338543192545574, 'train_runtime': 180.4461, 'train_samples_per_second': 6.65, 'train_steps_per_second': 0.416},config={'eval_delay': {'value': 0}, 'eval_on_start': {'value': False}, 'bf16': {'value': False}, 'hidden_size': {'value': 3072}, 'save_steps': {'value': 50}, 'is_decoder': {'value': False}, 'do_train': {'value': False}, 'use_mps_device': {'value': False}, 'initializer_range': {'value': 0.02}, 'use_liger': {'value': False}, 'sep_token_id': {'value': None}, 'fsdp_transformer_layer_cls_to_wrap': {'value': None}, 'fp16_opt_level': {'value': 'O1'}, 'exponential_decay_length_penalty': {'value': None}, 'max_grad_norm': {'value': 0.3}, 'save_only_model': {'value': False}, 'torchscript': {'value': False}, 'push_to_hub_token': {'value': '<PUSH_TO_HUB_TOKEN>'}, 'length_column_name': {'value': 'length'}, 'weight_decay': {'value': 0.001}, 'warmup_ratio': {'value': 0}, 'cross_attention_hidden_size': {'value': None}, 'per_device_train_batch_size': {'value': 2}, 'decoder_start_token_id': {'value': None}, 'ray_scope': {'value': 'last'}, 'hub_always_push': {'value': False}, 'min_length': {'value': 0}, 'per_device_eval_batch_size': {'value': 8}, 'include_for_metrics': {'value': []}, 'problem_type': {'value': None}, 'return_dict_in_generate': {'value': False}, 'local_rank': {'value': 0}, 'resid_pdrop': {'value': 0}, 'eos_token_id': {'value': 32000}, 'split_batches': {'value': None}, 'typical_p': {'value': 1}, 'batch_eval_metrics': {'value': False}, 'greater_is_better': {'value': None}, 'architectures': {'value': ['Phi3ForCausalLM']}, 'seed': {'value': 42}, 'eval_strategy': {'value': 'epoch'}, 'bf16_full_eval': {'value': False}, 'output_hidden_states': {'value': False}, 'average_tokens_across_devices': {'value': False}, 'use_cpu': {'value': False}, 'resume_from_checkpoint': {'value': None}, 'top_p': {'value': 1}, 'dataset_num_proc': {'value': None}, 'original_max_position_embeddings': {'value': 4096}, 'tpu_num_cores': {'value': None}, 'intermediate_size': {'value': 8192}, 'max_length': {'value': 20}, 'remove_unused_columns': {'value': False}, 'repetition_penalty': {'value': 1}, 'finetuning_task': {'value': None}, 'num_key_value_heads': {'value': 32}, 'log_on_each_node': {'value': True}, 'prediction_loss_only': {'value': False}, 'logging_dir': {'value': '/ceph/ssd/staff/schwinn/experiments/2025/capo_vlm/models/2024-12-17-14-45-07/0/trainer_logs'}, 'use_ipex': {'value': False}, 'tie_word_embeddings': {'value': False}, 'gradient_checkpointing': {'value': False}, 'max_position_embeddings': {'value': 4096}, 'bos_token_id': {'value': 1}, 'adam_beta2': {'value': 0.999}, 'dataloader_pin_memory': {'value': True}, 'rope_scaling': {'value': None}, 'metric_for_best_model': {'value': None}, 'push_to_hub': {'value': False}, 'torch_compile_mode': {'value': None}, 'logging_strategy': {'value': 'steps'}, 'ddp_backend': {'value': None}, 'group_by_length': {'value': False}, 'gradient_accumulation_steps': {'value': 8}, 'chars_per_token': {'value': '<CHARS_PER_TOKEN>'}, 'rope_theta': {'value': 10000}, 'remove_invalid_values': {'value': False}, 'gradient_checkpointing_kwargs': {'value': None}, 'rms_norm_eps': {'value': 1e-05}, 'pad_token_id': {'value': 32000}, 'dataset_text_field': {'value': 'text'}, 'add_cross_attention': {'value': False}, 'ddp_find_unused_parameters': {'value': None}, 'torch_compile_backend': {'value': None}, 'fp16': {'value': True}, 'chunk_size_feed_forward': {'value': 0}, 'do_predict': {'value': False}, 'push_to_hub_organization': {'value': None}, 'tokenizer_class': {'value': None}, 'dataloader_prefetch_factor': {'value': None}, 'output_scores': {'value': False}, 'hub_token': {'value': '<HUB_TOKEN>'}, 'fsdp_config': {'value': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}}, 'mp_parameters': {'value': ''}, 'id2label': {'value': {'0': 'LABEL_0', '1': 'LABEL_1'}}, 'neftune_noise_alpha': {'value': None}, 'ddp_bucket_cap_mb': {'value': None}, 'use_liger_kernel': {'value': False}, 'optim': {'value': 'paged_adamw_32bit'}, 'sliding_window': {'value': 2047}, '_name_or_path': {'value': 'microsoft/Phi-3-mini-4k-instruct'}, 'tpu_metrics_debug': {'value': False}, 'lr_scheduler_type': {'value': 'cosine'}, 'use_cache': {'value': True}, 'ignore_data_skip': {'value': False}, 'auto_find_batch_size': {'value': False}, 'label_smoothing_factor': {'value': 0}, 'eval_accumulation_steps': {'value': None}, 'max_seq_length': {'value': 128}, 'attention_bias': {'value': False}, 'task_specific_params': {'value': None}, 'torch_empty_cache_steps': {'value': None}, 'num_return_sequences': {'value': 1}, 'no_repeat_ngram_size': {'value': 0}, 'begin_suppress_tokens': {'value': None}, 'forced_eos_token_id': {'value': None}, 'adam_beta1': {'value': 0.9}, 'top_k': {'value': 50}, 'num_hidden_layers': {'value': 32}, 'save_strategy': {'value': 'steps'}, 'output_attentions': {'value': False}, 'prefix': {'value': None}, 'load_best_model_at_end': {'value': False}, 'adafactor': {'value': False}, 'dataloader_drop_last': {'value': False}, 'per_gpu_train_batch_size': {'value': None}, 'diversity_penalty': {'value': 0}, 'data_seed': {'value': None}, 'disable_tqdm': {'value': False}, 'fsdp_min_num_params': {'value': 0}, 'hidden_act': {'value': 'silu'}, 'num_of_sequences': {'value': 1024}, 'num_beam_groups': {'value': 1}, 'embd_pdrop': {'value': 0}, 'model/num_parameters': {'value': 3921742848}, 'save_safetensors': {'value': True}, 'warmup_steps': {'value': 0}, 'learning_rate': {'value': 0.0002}, 'adam_epsilon': {'value': 1e-08}, 'log_level_replica': {'value': 'warning'}, '_attn_implementation_autoset': {'value': True}, 'past_index': {'value': -1}, 'do_eval': {'value': True}, 'full_determinism': {'value': False}, 'hub_model_id': {'value': None}, 'include_num_input_tokens_seen': {'value': False}, 'temperature': {'value': 1}, 'jit_mode_eval': {'value': False}, 'logging_nan_inf_filter': {'value': True}, 'is_encoder_decoder': {'value': False}, 'transformers_version': {'value': '4.47.0'}, 'dataloader_num_workers': {'value': 0}, 'logging_first_step': {'value': False}, 'encoder_no_repeat_ngram_size': {'value': 0}, 'tie_encoder_decoder': {'value': False}, 'logging_steps': {'value': 25}, 'max_steps': {'value': -1}, 'num_train_epochs': {'value': 1}, 'overwrite_output_dir': {'value': False}, 'model_type': {'value': 'phi3'}, 'model_init_kwargs': {'value': None}, 'restore_callback_states_from_checkpoint': {'value': False}, 'ddp_timeout': {'value': 1800}, 'fsdp': {'value': []}, 'length_penalty': {'value': 1}, 'fp16_backend': {'value': 'auto'}, 'log_level': {'value': 'passive'}, 'push_to_hub_model_id': {'value': None}, 'label_names': {'value': None}, 'packing': {'value': False}, 'include_tokens_per_second': {'value': False}, 'save_total_limit': {'value': 1}, 'save_on_each_node': {'value': False}, 'tf32': {'value': None}, 'hub_strategy': {'value': 'every_save'}, 'optim_target_modules': {'value': None}, 'label2id': {'value': {'LABEL_1': 1, 'LABEL_0': 0}}, 'early_stopping': {'value': False}, 'dataset_batch_size': {'value': 1000}, 'include_inputs_for_metrics': {'value': False}, 'quantization_config': {'value': {'bnb_4bit_use_double_quant': False, 'load_in_8bit': False, '_load_in_4bit': True, 'llm_int8_skip_modules': ['img_projection', 'vision_model'], 'quant_method': 'BITS_AND_BYTES', 'llm_int8_threshold': 6, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'llm_int8_enable_fp32_cpu_offload': False, '_load_in_8bit': False, 'llm_int8_has_fp16_weight': False, 'bnb_4bit_quant_type': 'nf4'}}, 'num_beams': {'value': 1}, 'tf_legacy_loss': {'value': False}, 'eval_do_concat_batches': {'value': True}, 'run_name': {'value': '2024-12-17-14-45-07'}, 'hub_private_repo': {'value': None}, 'use_legacy_prediction_loop': {'value': False}, 'use_bfloat16': {'value': False}, 'optim_args': {'value': None}, 'vocab_size': {'value': 32064}, 'no_cuda': {'value': False}, 'per_gpu_eval_batch_size': {'value': None}, '_wandb': {'value': {'m': [{'1': 'train/global_step', '6': [3]}, {'1': 'train/pretrain_eval_harmless_loss', '5': 1, '6': [1]}, {'1': 'train/pretrain_eval_harmless_model_preparation_time', '5': 1, '6': [1]}, {'6': [1], '1': 'train/pretrain_eval_harmless_runtime', '5': 1}, {'5': 1, '6': [1], '1': 'train/pretrain_eval_harmless_samples_per_second'}, {'1': 'train/pretrain_eval_harmless_steps_per_second', '5': 1, '6': [1]}, {'1': 'train/retain_loss', '5': 1, '6': [1]}, {'1': 'train/epoch', '5': 1, '6': [1]}, {'1': 'train/attack_loss', '5': 1, '6': [1]}, {'5': 1, '6': [1], '1': 'train/away_loss'}, {'1': 'train/toward_loss', '5': 1, '6': [1]}, {'1': 'train/loss', '5': 1, '6': [1]}, {'6': [1], '1': 'train/grad_norm', '5': 1}, {'6': [1], '1': 'train/learning_rate', '5': 1}, {'1': 'eval/harmless_loss', '5': 1, '6': [1]}, {'1': 'eval/harmless_model_preparation_time', '5': 1, '6': [1]}, {'5': 1, '6': [1], '1': 'eval/harmless_runtime'}, {'5': 1, '6': [1], '1': 'eval/harmless_samples_per_second'}, {'5': 1, '6': [1], '1': 'eval/harmless_steps_per_second'}], 't': {'1': [1, 11, 41, 49, 50, 51, 55, 71, 84, 98], '2': [1, 11, 41, 49, 50, 51, 55, 71, 84, 98], '4': '3.12.4', '5': '0.17.3', '6': '4.47.0', '9': {'1': 'transformers_trainer'}, '3': [7, 13, 14, 19, 23, 62, 66], '8': [5], '13': 'linux-x86_64'}, 'cli_version': '0.17.3', 'is_kaggle_kernel': False, 'framework': 'huggingface', 'start_time': 1734443115, 'is_jupyter_run': False, 'python_version': '3.12.4', 'huggingface_version': '4.47.0'}}, 'bad_words_ids': {'value': None}, 'evaluation_strategy': {'value': None}, 'skip_memory_metrics': {'value': True}, 'dataloader_persistent_workers': {'value': False}, 'ddp_broadcast_buffers': {'value': None}, 'fp16_full_eval': {'value': False}, 'dispatch_batches': {'value': None}, 'peft_config': {'value': {'default': {'r': 64, 'megatron_core': 'megatron.core', 'init_lora_weights': True, 'base_model_name_or_path': 'microsoft/Phi-3-mini-4k-instruct', 'target_modules': ['model.layers.17.mlp.down_proj', 'model.layers.24.self_attn.qkv_proj', 'model.layers.20.mlp.gate_up_proj', 'model.layers.18.mlp.gate_up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.10.self_attn.qkv_proj', 'model.layers.31.mlp.down_proj', 'model.layers.0.mlp.gate_up_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.22.mlp.down_proj', 'model.layers.13.self_attn.qkv_proj', 'model.layers.16.mlp.gate_up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.18.self_attn.qkv_proj', 'model.layers.4.mlp.gate_up_proj', 'model.layers.15.mlp.gate_up_proj', 'model.layers.12.self_attn.qkv_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.14.mlp.gate_up_proj', 'model.layers.8.mlp.gate_up_proj', 'model.layers.22.mlp.gate_up_proj', 'model.layers.6.self_attn.qkv_proj', 'model.layers.24.mlp.down_proj', 'model.layers.13.mlp.down_proj', 'model.layers.27.self_attn.qkv_proj', 'model.layers.11.mlp.down_proj', 'model.layers.4.self_attn.qkv_proj', 'model.layers.0.self_attn.qkv_proj', 'model.layers.30.self_attn.qkv_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.27.mlp.gate_up_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.24.mlp.gate_up_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.mlp.gate_up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.16.mlp.down_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.29.self_attn.o_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.30.mlp.gate_up_proj', 'model.layers.19.self_attn.qkv_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.28.mlp.down_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.27.mlp.down_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.28.self_attn.o_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.5.mlp.down_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.12.mlp.down_proj', 'model.layers.17.mlp.gate_up_proj', 'model.layers.22.self_attn.qkv_proj', 'model.layers.31.self_attn.o_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.26.mlp.down_proj', 'model.layers.29.mlp.down_proj', 'model.layers.18.mlp.down_proj', 'model.layers.20.self_attn.qkv_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.2.mlp.down_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.8.mlp.down_proj', 'model.layers.21.self_attn.qkv_proj', 'model.layers.14.self_attn.qkv_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.16.self_attn.qkv_proj', 'model.layers.23.self_attn.qkv_proj', 'model.layers.11.mlp.gate_up_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.7.self_attn.qkv_proj', 'model.layers.17.self_attn.qkv_proj', 'model.layers.9.self_attn.qkv_proj', 'model.layers.26.self_attn.qkv_proj', 'model.layers.25.self_attn.qkv_proj', 'model.layers.31.self_attn.qkv_proj', 'model.layers.28.mlp.gate_up_proj', 'model.layers.19.mlp.gate_up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.30.mlp.down_proj', 'model.layers.29.self_attn.qkv_proj', 'model.layers.6.mlp.gate_up_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.5.self_attn.qkv_proj', 'model.layers.10.mlp.gate_up_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.8.self_attn.qkv_proj', 'model.layers.11.self_attn.qkv_proj', 'model.layers.10.mlp.down_proj', 'model.layers.7.mlp.down_proj', 'model.layers.1.self_attn.qkv_proj', 'model.layers.27.self_attn.o_proj', 'model.layers.20.mlp.down_proj', 'model.layers.25.mlp.gate_up_proj', 'model.layers.26.mlp.gate_up_proj', 'model.layers.31.mlp.gate_up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.29.mlp.gate_up_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.4.mlp.down_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.3.self_attn.qkv_proj', 'model.layers.13.mlp.gate_up_proj', 'model.layers.3.mlp.gate_up_proj', 'model.layers.25.mlp.down_proj', 'model.layers.2.mlp.gate_up_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.0.mlp.down_proj', 'model.layers.9.mlp.gate_up_proj', 'model.layers.21.mlp.gate_up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.28.self_attn.qkv_proj', 'model.layers.14.mlp.down_proj', 'model.layers.5.mlp.gate_up_proj', 'model.layers.7.mlp.gate_up_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.15.self_attn.qkv_proj', 'model.layers.19.mlp.down_proj', 'model.layers.30.self_attn.o_proj', 'model.layers.12.mlp.gate_up_proj', 'model.layers.2.self_attn.qkv_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.23.mlp.gate_up_proj'], 'revision': None, 'layer_replication': None, 'inference_mode': False, 'fan_in_fan_out': False, 'use_rslora': False, 'megatron_config': None, 'layers_to_transform': None, 'lora_alpha': 32, 'task_type': 'CAUSAL_LM', 'bias': 'none', 'lora_dropout': 0.1, 'use_dora': False, 'modules_to_save': None, 'auto_mapping': None, 'layers_pattern': None, 'peft_type': 'LORA'}}}, 'eval_steps': {'value': None}, 'return_dict': {'value': True}, 'eval_packing': {'value': None}, 'num_attention_heads': {'value': 32}, 'half_precision_backend': {'value': 'auto'}, 'report_to': {'value': ['tensorboard', 'wandb']}, 'torch_dtype': {'value': 'bfloat16'}, 'eval_use_gather_object': {'value': False}, 'output_dir': {'value': '/ceph/ssd/staff/schwinn/experiments/2025/capo_vlm/models/2024-12-17-14-45-07/0/trainer_output'}, 'deepspeed': {'value': None}, 'accelerator_config': {'value': {'non_blocking': False, 'use_seedable_sampler': True, 'even_batches': True, 'dispatch_batches': None, 'split_batches': False, 'gradient_accumulation_kwargs': None}}, 'do_sample': {'value': False}, 'attention_dropout': {'value': 0}, 'torchdynamo': {'value': None}, 'suppress_tokens': {'value': None}, 'auto_map': {'value': {'AutoModelForCausalLM': 'microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM', 'AutoConfig': 'microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config'}}, 'debug': {'value': []}, 'torch_compile': {'value': False}, 'forced_bos_token_id': {'value': None}},tags=[])
2024-12-17 15:02:08,251 INFO    SenderThread:1644618 [dir_watcher.py:__init__():211] watching files in: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files
2024-12-17 15:02:08,251 INFO    SenderThread:1644618 [sender.py:_start_run_threads():1188] run started: 2024-12-17-14-45-07 with start time 1734443925.132824
2024-12-17 15:02:08,251 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: summary_record
2024-12-17 15:02:08,252 INFO    SenderThread:1644618 [sender.py:_save_file():1454] saving file wandb-summary.json with policy end
2024-12-17 15:02:08,261 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: check_version
2024-12-17 15:02:08,261 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: check_version
2024-12-17 15:02:08,334 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: run_start
2024-12-17 15:02:08,345 DEBUG   HandlerThread:1644618 [system_info.py:__init__():26] System info init
2024-12-17 15:02:08,345 DEBUG   HandlerThread:1644618 [system_info.py:__init__():41] System info init done
2024-12-17 15:02:08,345 INFO    HandlerThread:1644618 [system_monitor.py:start():194] Starting system monitor
2024-12-17 15:02:08,345 INFO    SystemMonitor:1644618 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-12-17 15:02:08,346 INFO    SystemMonitor:1644618 [interfaces.py:start():188] Started cpu monitoring
2024-12-17 15:02:08,348 INFO    SystemMonitor:1644618 [interfaces.py:start():188] Started disk monitoring
2024-12-17 15:02:08,350 INFO    SystemMonitor:1644618 [interfaces.py:start():188] Started gpu monitoring
2024-12-17 15:02:08,351 INFO    SystemMonitor:1644618 [interfaces.py:start():188] Started memory monitoring
2024-12-17 15:02:08,352 INFO    SystemMonitor:1644618 [interfaces.py:start():188] Started network monitoring
2024-12-17 15:02:08,669 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: python_packages
2024-12-17 15:02:08,669 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: python_packages
2024-12-17 15:02:08,709 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: stop_status
2024-12-17 15:02:08,709 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: internal_messages
2024-12-17 15:02:08,710 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: partial_history
2024-12-17 15:02:08,710 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: server_info
2024-12-17 15:02:08,710 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: stop_status
2024-12-17 15:02:08,869 DEBUG   SenderThread:1644618 [sender.py:send():379] send: telemetry
2024-12-17 15:02:08,869 DEBUG   SenderThread:1644618 [sender.py:send():379] send: history
2024-12-17 15:02:08,869 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: summary_record
2024-12-17 15:02:08,870 INFO    SenderThread:1644618 [sender.py:_save_file():1454] saving file wandb-summary.json with policy end
2024-12-17 15:02:08,870 DEBUG   SenderThread:1644618 [sender.py:send():379] send: telemetry
2024-12-17 15:02:08,870 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: server_info
2024-12-17 15:02:09,137 DEBUG   SenderThread:1644618 [sender.py:send():379] send: exit
2024-12-17 15:02:09,137 INFO    SenderThread:1644618 [sender.py:send_exit():586] handling exit code: 0
2024-12-17 15:02:09,137 INFO    SenderThread:1644618 [sender.py:send_exit():588] handling runtime: 0
2024-12-17 15:02:09,139 INFO    SenderThread:1644618 [sender.py:_save_file():1454] saving file wandb-summary.json with policy end
2024-12-17 15:02:09,139 INFO    SenderThread:1644618 [sender.py:send_exit():594] send defer
2024-12-17 15:02:09,139 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,139 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 0
2024-12-17 15:02:09,139 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,139 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 0
2024-12-17 15:02:09,139 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 1
2024-12-17 15:02:09,139 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,139 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 1
2024-12-17 15:02:09,139 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,139 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 1
2024-12-17 15:02:09,139 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 2
2024-12-17 15:02:09,139 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,139 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 2
2024-12-17 15:02:09,139 INFO    HandlerThread:1644618 [system_monitor.py:finish():203] Stopping system monitor
2024-12-17 15:02:09,140 DEBUG   SystemMonitor:1644618 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2024-12-17 15:02:09,140 DEBUG   SystemMonitor:1644618 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2024-12-17 15:02:09,140 DEBUG   SystemMonitor:1644618 [system_monitor.py:_start():183] Publishing last batch of metrics
2024-12-17 15:02:09,141 INFO    HandlerThread:1644618 [interfaces.py:finish():200] Joined cpu monitor
2024-12-17 15:02:09,141 INFO    HandlerThread:1644618 [interfaces.py:finish():200] Joined disk monitor
2024-12-17 15:02:09,251 INFO    Thread-12 :1644618 [dir_watcher.py:_on_file_created():271] file/dir created: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/requirements.txt
2024-12-17 15:02:09,251 INFO    Thread-12 :1644618 [dir_watcher.py:_on_file_created():271] file/dir created: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/wandb-summary.json
2024-12-17 15:02:09,303 INFO    HandlerThread:1644618 [interfaces.py:finish():200] Joined gpu monitor
2024-12-17 15:02:09,303 INFO    HandlerThread:1644618 [interfaces.py:finish():200] Joined memory monitor
2024-12-17 15:02:09,303 INFO    HandlerThread:1644618 [interfaces.py:finish():200] Joined network monitor
2024-12-17 15:02:09,304 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,304 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 2
2024-12-17 15:02:09,304 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 3
2024-12-17 15:02:09,304 DEBUG   SenderThread:1644618 [sender.py:send():379] send: stats
2024-12-17 15:02:09,304 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,304 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 3
2024-12-17 15:02:09,304 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,304 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 3
2024-12-17 15:02:09,304 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 4
2024-12-17 15:02:09,304 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,304 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 4
2024-12-17 15:02:09,304 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,304 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 4
2024-12-17 15:02:09,304 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 5
2024-12-17 15:02:09,304 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,304 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 5
2024-12-17 15:02:09,305 DEBUG   SenderThread:1644618 [sender.py:send():379] send: summary
2024-12-17 15:02:09,306 INFO    SenderThread:1644618 [sender.py:_save_file():1454] saving file wandb-summary.json with policy end
2024-12-17 15:02:09,306 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,306 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 5
2024-12-17 15:02:09,306 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 6
2024-12-17 15:02:09,306 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,306 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 6
2024-12-17 15:02:09,307 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,307 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 6
2024-12-17 15:02:09,309 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: status_report
2024-12-17 15:02:09,544 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 7
2024-12-17 15:02:09,544 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,544 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 7
2024-12-17 15:02:09,544 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,544 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 7
2024-12-17 15:02:09,544 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 8
2024-12-17 15:02:09,544 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,544 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 8
2024-12-17 15:02:09,544 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,544 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 8
2024-12-17 15:02:09,544 INFO    SenderThread:1644618 [job_builder.py:build():440] Attempting to build job artifact
2024-12-17 15:02:09,545 WARNING SenderThread:1644618 [job_builder.py:_log_if_verbose():274] Ensure read and write access to run files dir: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables
2024-12-17 15:02:09,545 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 9
2024-12-17 15:02:09,545 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:09,545 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 9
2024-12-17 15:02:09,545 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:09,545 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 9
2024-12-17 15:02:09,545 INFO    SenderThread:1644618 [dir_watcher.py:finish():358] shutting down directory watcher
2024-12-17 15:02:10,137 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: poll_exit
2024-12-17 15:02:10,250 INFO    Thread-12 :1644618 [dir_watcher.py:_on_file_modified():288] file/dir modified: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/wandb-summary.json
2024-12-17 15:02:10,251 INFO    SenderThread:1644618 [dir_watcher.py:_on_file_modified():288] file/dir modified: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/config.yaml
2024-12-17 15:02:10,251 INFO    SenderThread:1644618 [dir_watcher.py:finish():388] scan: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files
2024-12-17 15:02:10,252 INFO    SenderThread:1644618 [dir_watcher.py:finish():402] scan save: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/requirements.txt requirements.txt
2024-12-17 15:02:10,252 INFO    SenderThread:1644618 [dir_watcher.py:finish():402] scan save: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/config.yaml config.yaml
2024-12-17 15:02:10,252 INFO    SenderThread:1644618 [dir_watcher.py:finish():402] scan save: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/wandb-summary.json wandb-summary.json
2024-12-17 15:02:10,253 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 10
2024-12-17 15:02:10,253 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: poll_exit
2024-12-17 15:02:10,254 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:10,254 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 10
2024-12-17 15:02:10,256 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:10,256 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 10
2024-12-17 15:02:10,256 INFO    SenderThread:1644618 [file_pusher.py:finish():169] shutting down file pusher
2024-12-17 15:02:10,748 INFO    wandb-upload_0:1644618 [upload_job.py:push():130] Uploaded file /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/requirements.txt
2024-12-17 15:02:10,755 INFO    wandb-upload_2:1644618 [upload_job.py:push():130] Uploaded file /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/wandb-summary.json
2024-12-17 15:02:10,756 INFO    wandb-upload_1:1644618 [upload_job.py:push():130] Uploaded file /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/files/config.yaml
2024-12-17 15:02:10,956 INFO    Thread-11 (_thread_body):1644618 [sender.py:transition_state():614] send defer: 11
2024-12-17 15:02:10,957 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:10,957 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 11
2024-12-17 15:02:10,957 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:10,957 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 11
2024-12-17 15:02:10,957 INFO    SenderThread:1644618 [file_pusher.py:join():175] waiting for file pusher
2024-12-17 15:02:10,957 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 12
2024-12-17 15:02:10,957 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:10,957 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 12
2024-12-17 15:02:10,958 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:10,958 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 12
2024-12-17 15:02:10,958 INFO    SenderThread:1644618 [file_stream.py:finish():601] file stream finish called
2024-12-17 15:02:11,138 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: poll_exit
2024-12-17 15:02:11,638 INFO    SenderThread:1644618 [file_stream.py:finish():605] file stream finish is done
2024-12-17 15:02:11,638 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 13
2024-12-17 15:02:11,639 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: poll_exit
2024-12-17 15:02:11,639 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:11,639 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 13
2024-12-17 15:02:11,639 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:11,639 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 13
2024-12-17 15:02:11,639 INFO    SenderThread:1644618 [sender.py:transition_state():614] send defer: 14
2024-12-17 15:02:11,639 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: defer
2024-12-17 15:02:11,639 INFO    HandlerThread:1644618 [handler.py:handle_request_defer():184] handle defer: 14
2024-12-17 15:02:11,639 DEBUG   SenderThread:1644618 [sender.py:send():379] send: final
2024-12-17 15:02:11,639 DEBUG   SenderThread:1644618 [sender.py:send():379] send: footer
2024-12-17 15:02:11,639 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: defer
2024-12-17 15:02:11,640 INFO    SenderThread:1644618 [sender.py:send_request_defer():610] handle sender defer: 14
2024-12-17 15:02:11,640 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: poll_exit
2024-12-17 15:02:11,640 DEBUG   SenderThread:1644618 [sender.py:send_request():406] send_request: poll_exit
2024-12-17 15:02:11,640 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: internal_messages
2024-12-17 15:02:11,641 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: get_summary
2024-12-17 15:02:11,642 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: sampled_history
2024-12-17 15:02:11,643 DEBUG   HandlerThread:1644618 [handler.py:handle_request():158] handle_request: shutdown
2024-12-17 15:02:11,643 INFO    HandlerThread:1644618 [handler.py:finish():882] shutting down handler
2024-12-17 15:02:12,640 INFO    WriterThread:1644618 [datastore.py:close():296] close: /ceph/ssd/staff/schwinn/projects/25/llm-quick-check/wandb/run-20241217_150206-2024-12-17-14-45-07/run-2024-12-17-14-45-07.wandb
2024-12-17 15:02:12,640 INFO    SenderThread:1644618 [sender.py:finish():1608] shutting down sender
2024-12-17 15:02:12,640 INFO    SenderThread:1644618 [file_pusher.py:finish():169] shutting down file pusher
2024-12-17 15:02:12,641 INFO    SenderThread:1644618 [file_pusher.py:join():175] waiting for file pusher
