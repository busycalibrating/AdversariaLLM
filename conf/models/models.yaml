##### Custom models #####
# Define common configurations using YAML anchors
base_llama3_1_8b_rf: &base_llama3_1_8b_rf
  tokenizer_id: meta-llama/Llama-3.1-8B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
  lora_cfg:
    merge_lora: True
    base_name: meta-llama/Llama-3.1-8B-Instruct
    manual_untie_embeddings: False

base_llama3_2_rf: &base_llama3_2_rf
  tokenizer_id: meta-llama/Llama-3.2-3B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
  lora_cfg:
    merge_lora: True
    base_name: meta-llama/Llama-3.2-3B-Instruct
    manual_untie_embeddings: True

base_continuous_at_llama3_2: &base_continuous_at_llama3_2
  tokenizer_id: meta-llama/Llama-3.2-3B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
  lora_cfg:
    merge_lora: True
    base_name: meta-llama/Llama-3.2-3B-Instruct
    manual_untie_embeddings: False

base_phi3_5_rf: &base_phi3_5_rf
  tokenizer_id: microsoft/Phi-3.5-mini-instruct
  short_name: Phi 3.5
  developer_name: Microsoft
  compile: False
  dtype: bfloat16
  chat_template: phi-3  # same as phi-3 
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
  lora_cfg:
    merge_lora: True
    base_name: microsoft/Phi-3.5-mini-instruct
    manual_untie_embeddings: False

# Model configurations using aliases
redflag-tokens/llama3-1-8b-rf-v1:
  <<: *base_llama3_1_8b_rf
  id: redflag-tokens/llama3.1-8B-RF-7658201-baseline

redflag-tokens/llama3-1-8b-rf-multi:
  <<: *base_llama3_1_8b_rf
  id: redflag-tokens/llama3.1-8B-RF-7683325-multi

redflag-tokens/llama3-2-rf-AT-single-morekl-rampup:
  <<: *base_llama3_2_rf
  id: /network/scratch/d/david-a.dobre/2024/new_redflag_llm/outputs/llama32_final/AT_single_more-kl_rampup
  # id: /home/ddobre/scratch/misc_models/AT_single_more-kl_rampup

redflag-tokens/llama3-2-rf-filter5-v3:
  <<: *base_llama3_2_rf
  id: redflag-tokens/llama3.2-RF-filter5-7481078-chkpt-1000

redflag-tokens/llama3-2-rf-v3:
  <<: *base_llama3_2_rf
  id: redflag-tokens/llama3.2-RF-7466465-chkpt-1000

redflag-tokens/llama3-2-rf-fixed-pos-v2:
  <<: *base_llama3_2_rf
  id: redflag-tokens/fixed-pos-baseline-7069757-chkpt-625

redflag-tokens/llama3-2-rf-v2-offset:
  <<: *base_llama3_2_rf
  id: redflag-tokens/llama3.2-rf-offset16-7068555-chkpt-625

redflag-tokens/llama3-2-rf-v2:
  <<: *base_llama3_2_rf
  id: redflag-tokens/llama3.2-rf-7040402-chkpt-625

redflag-tokens/llama3-2-rf-AT:
  <<: *base_llama3_2_rf
  id: redflag-tokens/llama3.2-AT-6910983-chkpt-575

redflag-tokens/llama3-2-fixed-pos:
  <<: *base_llama3_2_rf
  id: redflag-tokens/llama3.2-fixed-pos-baseline-5969033

redflag-tokens/llama3-2-rf:
  <<: *base_llama3_2_rf
  id: redflag-tokens/llama3.2-rf-5971790-chkpt-625

continuous-at/llama3-2-cat:
  <<: *base_continuous_at_llama3_2
  id: ContinuousAT/llama3.2-3B-IT-rf-cat

continuous-at/llama3-2-cat-v2:
  <<: *base_continuous_at_llama3_2
  id: ContinuousAT/fixed-llama3.2-3B-IT-rf-cat

redflag-tokens/phi3-5-rf:
  <<: *base_phi3_5_rf
  id: redflag-tokens/phi3-5-5975292-chkpt-800

redflag-tokens/mistralv3-rf:
  id: redflag-tokens/mistralv3-rf-5977218-chkpt-275
  tokenizer_id: mistralai/Mistral-7B-Instruct-v0.3
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: mistral-instruct
  trust_remote_code: True


##### default models #####
google/gemma-2-2b-it:
  id: google/gemma-2-2b-it
  tokenizer_id: google/gemma-2-2b-it
  short_name: Gemma
  developer_name: Google
  compile: False
  dtype: bfloat16
  chat_template: gemma-it
  trust_remote_code: True
google/gemma-2-9b-it:
  id: google/gemma-2-9b-it
  tokenizer_id: google/gemma-2-9b-it
  short_name: Gemma
  developer_name: Google
  compile: False
  dtype: bfloat16
  chat_template: gemma-it
  trust_remote_code: True
google/gemma-3-1b-it:
  id: google/gemma-3-1b-it
  tokenizer_id: google/gemma-3-1b-it
  short_name: Gemma
  developer_name: Google
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
google/gemma-3-4b-it:
  id: google/gemma-3-4b-it
  tokenizer_id: google/gemma-3-4b-it
  short_name: Gemma
  developer_name: Google
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
google/gemma-3-12b-it:
  id: google/gemma-3-12b-it
  tokenizer_id: google/gemma-3-12b-it
  short_name: Gemma
  developer_name: Google
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
google/gemma-3-27b-it:
  id: google/gemma-3-27b-it
  tokenizer_id: google/gemma-3-27b-it
  short_name: Gemma
  developer_name: Google
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
mistralai/Mistral-7B-Instruct-v0.3:
  id: mistralai/Mistral-7B-Instruct-v0.3
  tokenizer_id: mistralai/Mistral-7B-Instruct-v0.3
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: mistral-instruct
  trust_remote_code: True
berkeley-nest/Starling-LM-7B-alpha:
  id: berkeley-nest/Starling-LM-7B-alpha
  tokenizer_id: openchat/openchat_3.5
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: openchat-3.5
  trust_remote_code: True
meta-llama/Meta-Llama-3.1-8B-Instruct:
  id: meta-llama/Meta-Llama-3.1-8B-Instruct
  tokenizer_id: meta-llama/Meta-Llama-3.1-8B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
meta-llama/Llama-3.2-1B-Instruct:
  id: meta-llama/Llama-3.2-1B-Instruct
  tokenizer_id: meta-llama/Llama-3.2-1B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
meta-llama/Llama-3.2-3B-Instruct:
  id: meta-llama/Llama-3.2-3B-Instruct
  tokenizer_id: meta-llama/Llama-3.2-3B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
NousResearch/Hermes-2-Pro-Llama-3-8B:
  id: NousResearch/Hermes-2-Pro-Llama-3-8B
  tokenizer_id: NousResearch/Hermes-2-Pro-Llama-3-8B
  short_name: Hermes
  developer_name: NousResearch
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
allenai/Llama-3.1-Tulu-3-8B-DPO:
  id: allenai/Llama-3.1-Tulu-3-8B-DPO
  tokenizer_id: allenai/Llama-3.1-Tulu-3-8B-DPO
  short_name: Llama
  developer_name: AllenAI
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated:
  id: mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated
  tokenizer_id: meta-llama/Meta-Llama-3.1-8B-Instruct
  short_name: Llama
  developer_name: mlabonne
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
meta-llama/Meta-Llama-3-8B-Instruct:
  id: meta-llama/Meta-Llama-3-8B-Instruct
  tokenizer_id: meta-llama/Meta-Llama-3-8B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
LLM-LAT/robust-llama3-8b-instruct:
  id: LLM-LAT/robust-llama3-8b-instruct
  tokenizer_id: LLM-LAT/robust-llama3-8b-instruct
  short_name: Llama
  developer_name: LLM-LAT
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
qwen/Qwen2-7B-Instruct:
  id: qwen/Qwen2-7B-Instruct
  tokenizer_id: qwen/Qwen2-7B-Instruct
  short_name: Qwen2
  developer_name: Alibaba
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
HuggingFaceH4/zephyr-7b-beta:
  id: HuggingFaceH4/zephyr-7b-beta
  tokenizer_id: HuggingFaceH4/zephyr-7b-beta
  short_name: Zephyr
  developer_name: Hugging Face
  compile: False
  dtype: bfloat16
  chat_template: zephyr
  trust_remote_code: True
meta-llama/Llama-2-7b-chat-hf:
  id: meta-llama/Llama-2-7b-chat-hf
  tokenizer_id: meta-llama/Llama-2-7b-chat-hf
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-2-chat
  trust_remote_code: True
Unispac/Llama2-7B-Chat-Augmented:
  id: Unispac/Llama2-7B-Chat-Augmented
  tokenizer_id: Unispac/Llama2-7B-Chat-Augmented
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-2-chat
  trust_remote_code: True
ContinuousAT/Llama-2-7B-CAT:
  id: ContinuousAT/Llama-2-7B-CAT
  tokenizer_id: meta-llama/Llama-2-7b-chat-hf
  short_name: Llama
  developer_name: ContinuousAT
  attn_implementation: null
  compile: False
  dtype: bfloat16
  chat_template: llama-2-chat
  trust_remote_code: True
ContinuousAT/Zephyr-CAT:
  id: ContinuousAT/Zephyr-CAT
  tokenizer_id: HuggingFaceH4/zephyr-7b-beta
  short_name: Zephyr
  developer_name: ContinuousAT
  attn_implementation: null
  compile: False
  dtype: bfloat16
  chat_template: zephyr
  trust_remote_code: True
ContinuousAT/Phi-CAT:
  id: ContinuousAT/Phi-CAT
  tokenizer_id: microsoft/Phi-3-mini-4k-instruct
  short_name: Phi
  developer_name: ContinuousAT
  compile: False
  dtype: bfloat16
  chat_template: phi-3
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
microsoft/Phi-3-mini-4k-instruct:
  id: microsoft/Phi-3-mini-4k-instruct
  tokenizer_id: microsoft/Phi-3-mini-4k-instruct
  short_name: Phi
  developer_name: Microsoft
  compile: False
  dtype: bfloat16
  chat_template: phi-3
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
microsoft/phi-4:
  id: microsoft/phi-4
  tokenizer_id: microsoft/phi-4
  short_name: Phi
  developer_name: Microsoft
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
cais/zephyr_7b_r2d2:
  id: cais/zephyr_7b_r2d2
  tokenizer_id: cais/zephyr_7b_r2d2
  short_name: R2D2
  developer_name: CAIS
  compile: False
  dtype: bfloat16
  chat_template: zephyr
  trust_remote_code: True
GraySwanAI/Llama-3-8B-Instruct-RR:
  id: GraySwanAI/Llama-3-8B-Instruct-RR
  tokenizer_id: GraySwanAI/Llama-3-8B-Instruct-RR
  short_name: Llama
  developer_name: GraySwanAI
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
GraySwanAI/Mistral-7B-Instruct-RR:
  id: GraySwanAI/Mistral-7B-Instruct-RR
  tokenizer_id: GraySwanAI/Mistral-7B-Instruct-RR
  short_name: Mistral
  developer_name: GraySwanAI
  compile: False
  dtype: bfloat16
  chat_template: mistral-instruct
  trust_remote_code: True
lmsys/vicuna-13b-v1.5:
  id: lmsys/vicuna-13b-v1.5
  tokenizer_id: lmsys/vicuna-13b-v1.5
  short_name: Vicuna
  developer_name: lmsys
  compile: False
  dtype: bfloat16
  chat_template: vicuna
  trust_remote_code: True
lmsys/vicuna-7b-v1.5:
  id: lmsys/vicuna-7b-v1.5
  tokenizer_id: lmsys/vicuna-7b-v1.5
  short_name: Vicuna
  developer_name: lmsys
  compile: False
  dtype: bfloat16
  chat_template: vicuna
  trust_remote_code: True
mistralai/Mistral-Nemo-Instruct-2407:
  id: mistralai/Mistral-Nemo-Instruct-2407
  tokenizer_id: mistralai/Mistral-Nemo-Instruct-2407
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
mistralai/Ministral-8B-Instruct-2410:
  id: mistralai/Ministral-8B-Instruct-2410
  tokenizer_id: mistralai/Ministral-8B-Instruct-2410
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
openai/gpt-oss-20b:
  id: openai/gpt-oss-20b
  tokenizer_id: openai/gpt-oss-20b
  short_name: GPT
  developer_name: OpenAI
  compile: False
  dtype: null
  chat_template: null
  trust_remote_code: True
openai/gpt-oss-120b:
  id: openai/gpt-oss-120b
  tokenizer_id: openai/gpt-oss-120b
  short_name: GPT
  developer_name: OpenAI
  compile: False
  dtype: null
  chat_template: null
  trust_remote_code: True
GSAI-ML/LLaDA-8B-Instruct:
  id: GSAI-ML/LLaDA-8B-Instruct
  tokenizer_id: GSAI-ML/LLaDA-8B-Instruct
  short_name: LLaDA
  developer_name: GSAI-ML
  compile: False
  dtype: bfloat16
  trust_remote_code: True
Qwen/Qwen2.5-0.5B-Instruct:
  id: Qwen/Qwen2.5-0.5B-Instruct
  tokenizer_id: Qwen/Qwen2.5-0.5B-Instruct
  short_name: Qwen2.5
  developer_name: Qwen
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
