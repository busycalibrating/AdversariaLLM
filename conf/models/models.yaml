##### Custom models #####
redflag-tokens/llama3-2-rf:
  id: redflag-tokens/llama3.2-rf-5971790-chkpt-625
  # id: redflag-tokens/llama3.2-rf-5870512-chkpt-200
  tokenizer_id: meta-llama/Llama-3.2-3B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
  lora_cfg:
    merge_lora: True
    base_name: meta-llama/Llama-3.2-3B-Instruct
    manual_untie_embeddings: True
redflag-tokens/phi3-5-rf:
  id: redflag-tokens/phi3-5-5975292-chkpt-800
  tokenizer_id: microsoft/Phi-3.5-mini-instruct
  short_name: Phi 3.5
  developer_name: Microsoft
  compile: False
  dtype: bfloat16
  chat_template: phi-3  # same as phi-3 
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
redflag-tokens/mistralv3-rf:
  id: redflag-tokens/mistralv3-rf-5977218-chkpt-275
  tokenizer_id: mistralai/Mistral-7B-Instruct-v0.3
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: mistral-instruct
  trust_remote_code: True

##### Base models #####
google/gemma-2-2b-it:
  id: google/gemma-2-2b-it
  tokenizer_id: google/gemma-2-2b-it
  short_name: Gemma
  developer_name: Google
  compile: False
  dtype: bfloat16
  chat_template: gemma-it
  trust_remote_code: True
mistralai/Mistral-7B-Instruct-v0.3:
  id: mistralai/Mistral-7B-Instruct-v0.3
  tokenizer_id: mistralai/Mistral-7B-Instruct-v0.3
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: mistral-instruct
  trust_remote_code: True
berkeley-nest/Starling-LM-7B-alpha:
  id: berkeley-nest/Starling-LM-7B-alpha
  tokenizer_id: openchat/openchat_3.5
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: openchat-3.5
  trust_remote_code: True
meta-llama/Meta-Llama-3.1-8B-Instruct:
  id: meta-llama/Meta-Llama-3.1-8B-Instruct
  tokenizer_id: meta-llama/Meta-Llama-3.1-8B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
meta-llama/Llama-3.2-1B-Instruct:
  id: meta-llama/Llama-3.2-1B-Instruct
  tokenizer_id: meta-llama/Llama-3.2-1B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
meta-llama/Llama-3.2-3B-Instruct:
  id: meta-llama/Llama-3.2-3B-Instruct
  tokenizer_id: meta-llama/Llama-3.2-3B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
NousResearch/Hermes-2-Pro-Llama-3-8B:
  id: NousResearch/Hermes-2-Pro-Llama-3-8B
  tokenizer_id: NousResearch/Hermes-2-Pro-Llama-3-8B
  short_name: Hermes
  developer_name: NousResearch
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
allenai/Llama-3.1-Tulu-3-8B-DPO:
  id: allenai/Llama-3.1-Tulu-3-8B-DPO
  tokenizer_id: allenai/Llama-3.1-Tulu-3-8B-DPO
  short_name: Llama
  developer_name: AllenAI
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
meta-llama/Meta-Llama-3-8B-Instruct:
  id: meta-llama/Meta-Llama-3-8B-Instruct
  tokenizer_id: meta-llama/Meta-Llama-3-8B-Instruct
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
LLM-LAT/robust-llama3-8b-instruct:
  id: LLM-LAT/robust-llama3-8b-instruct
  tokenizer_id: LLM-LAT/robust-llama3-8b-instruct
  short_name: Llama
  developer_name: LLM-LAT
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
qwen/Qwen2-7B-Instruct:
  id: qwen/Qwen2-7B-Instruct
  tokenizer_id: qwen/Qwen2-7B-Instruct
  short_name: Qwen2
  developer_name: Alibaba
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
HuggingFaceH4/zephyr-7b-beta:
  id: HuggingFaceH4/zephyr-7b-beta
  tokenizer_id: HuggingFaceH4/zephyr-7b-beta
  short_name: Zephyr
  developer_name: Hugging Face
  compile: False
  dtype: bfloat16
  chat_template: zephyr
  trust_remote_code: True
meta-llama/Llama-2-7b-chat-hf:
  id: meta-llama/Llama-2-7b-chat-hf
  tokenizer_id: meta-llama/Llama-2-7b-chat-hf
  short_name: Llama
  developer_name: Meta
  compile: False
  dtype: bfloat16
  chat_template: llama-2-chat
  trust_remote_code: True
ContinuousAT/Llama-2-7B-CAT:
  id: ContinuousAT/Llama-2-7B-CAT
  tokenizer_id: meta-llama/Llama-2-7b-chat-hf
  short_name: Llama
  developer_name: ContinuousAT
  attn_implementation: null
  compile: False
  dtype: bfloat16
  chat_template: llama-2-chat
  trust_remote_code: True
ContinuousAT/Zephyr-CAT:
  id: ContinuousAT/Zephyr-CAT
  tokenizer_id: HuggingFaceH4/zephyr-7b-beta
  short_name: Zephyr
  developer_name: ContinuousAT
  attn_implementation: null
  compile: False
  dtype: bfloat16
  chat_template: zephyr
  trust_remote_code: True
ContinuousAT/Phi-CAT:
  id: ContinuousAT/Phi-CAT
  tokenizer_id: microsoft/Phi-3-mini-4k-instruct
  short_name: Phi
  developer_name: ContinuousAT
  compile: False
  dtype: bfloat16
  chat_template: phi-3
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
microsoft/Phi-3-mini-4k-instruct:
  id: microsoft/Phi-3-mini-4k-instruct
  tokenizer_id: microsoft/Phi-3-mini-4k-instruct
  short_name: Phi
  developer_name: Microsoft
  compile: False
  dtype: bfloat16
  chat_template: phi-3
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
microsoft/phi-4:
  id: microsoft/phi-4
  tokenizer_id: microsoft/phi-4
  short_name: Phi
  developer_name: Microsoft
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: False  # can't use torch's spda otherwise for some reason!
cais/zephyr_7b_r2d2:
  id: cais/zephyr_7b_r2d2
  tokenizer_id: cais/zephyr_7b_r2d2
  short_name: R2D2
  developer_name: CAIS
  compile: False
  dtype: bfloat16
  chat_template: zephyr
  trust_remote_code: True
GraySwanAI/Llama-3-8B-Instruct-RR:
  id: GraySwanAI/Llama-3-8B-Instruct-RR
  tokenizer_id: GraySwanAI/Llama-3-8B-Instruct-RR
  short_name: Llama
  developer_name: GraySwanAI
  compile: False
  dtype: bfloat16
  chat_template: llama-3-instruct
  trust_remote_code: True
GraySwanAI/Mistral-7B-Instruct-RR:
  id: GraySwanAI/Mistral-7B-Instruct-RR
  tokenizer_id: GraySwanAI/Mistral-7B-Instruct-RR
  short_name: Mistral
  developer_name: GraySwanAI
  compile: False
  dtype: bfloat16
  chat_template: mistral-instruct
  trust_remote_code: True
lmsys/vicuna-13b-v1.5:
  id: lmsys/vicuna-13b-v1.5
  tokenizer_id: lmsys/vicuna-13b-v1.5
  short_name: Vicuna
  developer_name: lmsys
  compile: False
  dtype: bfloat16
  chat_template: vicuna
  trust_remote_code: True
lmsys/vicuna-7b-v1.5:
  id: lmsys/vicuna-7b-v1.5
  tokenizer_id: lmsys/vicuna-7b-v1.5
  short_name: Vicuna
  developer_name: lmsys
  compile: False
  dtype: bfloat16
  chat_template: vicuna
  trust_remote_code: True
mistralai/Mistral-Nemo-Instruct-2407:
  id: mistralai/Mistral-Nemo-Instruct-2407
  tokenizer_id: mistralai/Mistral-Nemo-Instruct-2407
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
mistralai/Ministral-8B-Instruct-2410:
  id: mistralai/Ministral-8B-Instruct-2410
  tokenizer_id: mistralai/Ministral-8B-Instruct-2410
  short_name: Mistral
  developer_name: Mistral AI
  compile: False
  dtype: bfloat16
  chat_template: null
  trust_remote_code: True
