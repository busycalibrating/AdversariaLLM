_default:
  generation_config:
    temperature: 0.0
    top_p: 1.0
    top_k: 0
    max_new_tokens: 256
    num_return_sequences: 1
  seed: 0

actor:
  name: actor
  type: discrete
  placement: multi-turn
  seed: ${attacks._default.seed}
  generation_config: ${attacks._default.generation_config}
  version: 0.0.4
  attack_model:
    temperature: 0.0
    use_api: false
    api_model_name: null # gpt-4o
    id: mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated
    tokenizer_id: meta-llama/Meta-Llama-3.1-8B-Instruct
    short_name: Llama
    developer_name: mlabonne
    compile: False
    dtype: bfloat16
    chat_template: llama-3-instruct
    trust_remote_code: True
  judge_model:
    use_api: false
    api_model_name: null # gpt-4o
    target_model_holder: Meta
    id: mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated
    tokenizer_id: meta-llama/Meta-Llama-3.1-8B-Instruct
    short_name: Llama
    developer_name: mlabonne
    compile: False
    dtype: bfloat16
    chat_template: llama-3-instruct
    trust_remote_code: True
  actor_num: 3
  early_stop: true
  dynamic_modify: true
ample_gcg:
  name: ample_gcg
  type: discrete
  version: 0.0.1
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 200
  prompter_lm:
    id: osunlp/AmpleGCG-llama2-sourced-llama2-7b-chat
    tokenizer_id: osunlp/AmpleGCG-llama2-sourced-llama2-7b-chat
    chat_template: null
    short_name: ample_gcg
    developer_name: osunlp
    batch_size: 2
    dtype: bfloat16
    attn_implementation: null
    trust_remote_code: True
    compile: True
    generation_config:
      do_sample: false
      max_new_tokens: 20
      min_new_tokens: 20
      diversity_penalty: 1.0
autodan:
  name: autodan
  type: discrete
  version: 0.0.1
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 100
  early_stopping_threshold: 0
  batch_size: 128
  eval_steps: 5
  num_elites: 0.05
  crossover: 0.5
  num_points: 5
  mutation: 0.01
  mutate_model:
    id: null
    tokenizer_id: null
    short_name: null
    developer_name: null
    chat_template: null
    dtype: bfloat16
    compile: false
    trust_remote_code: True
beast:
  name: beast
  type: discrete
  version: 0.0.1
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 40
  optim_str_init: ""
  k1: 15
  k2: 15
  search_temperature: 1.0
  allow_non_ascii: True
  allow_special: False
  use_prefix_cache: True
  mask_undecided_tokens: False
bon:
  name: bon
  type: discrete
  version: 0.0.1
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 1000
  sigma: 0.4
  word_scrambling: true
  random_capitalization: true
  ascii_perturbation: true
direct:
  name: direct
  type: discrete
  version: 0.0.1
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
gcg:
  name: gcg
  type: discrete
  version: 0.0.1
  placement: suffix
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 250
  batch_size: 512
  optim_str_init: "x x x x x x x x x x x x x x x x x x x x" # all tested tokenizers convert this to exactly 20 tokens
  search_width: 512
  topk: 256
  n_replace: 1
  buffer_size: 0
  loss: ce
  use_constrained_gradient: False
  mellowmax_alpha: 1.0
  early_stop: False
  use_prefix_cache: True
  allow_non_ascii: False
  allow_special: False
  filter_ids: True
  verbosity: WARNING
  token_selection: default
  grow_target: False
  grad_smoothing: 1
  grad_momentum: 0.0   # 0.5 works quite well
gcg_refusal:
  name: gcg_refusal
  type: discrete
  version: 0.0.1
  placement: suffix
  max_new_tokens: ${attacks._default.generation_config.max_new_tokens}
  seed: ${attacks._default.seed}
  num_steps: 250
  batch_size: 512
  optim_str_init: "x x x x x x x x x x x x x x x x x x x x" # all tested tokenizers convert this to exactly 20 tokens
  search_width: 512
  topk: 256
  n_replace: 1
  buffer_size: 0
  use_mellowmax: False
  use_constrained_gradient: False
  mellowmax_alpha: 1.0
  early_stop: False
  use_prefix_cache: True
  allow_non_ascii: False
  allow_special: False
  filter_ids: True
  verbosity: WARNING
  token_selection: default
  max_new_target_tokens: 64
  grow_target: False
gcg_judge:
  name: gcg_judge
  type: discrete
  version: 0.0.1
  placement: suffix
  max_new_tokens: ${attacks._default.generation_config.max_new_tokens}
  seed: ${attacks._default.seed}
  num_steps: 250
  batch_size: 512
  optim_str_init: "x x x x x x x x x x x x x x x x x x x x" # all tested tokenizers convert this to exactly 20 tokens
  search_width: 512
  topk: 256
  n_replace: 1
  buffer_size: 0
  use_constrained_gradient: False
  early_stop: False
  use_prefix_cache: True
  allow_non_ascii: False
  allow_special: False
  filter_ids: True
  verbosity: WARNING
  token_selection: default
gcg_reinforce:
  name: gcg_reinforce
  type: discrete
  version: 0.0.1
  placement: suffix
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 500
  optim_str_init: "! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !" # initialization for REINFORCE
  search_width: 512
  topk: 256
  n_replace: 1
  buffer_size: 0
  loss: "ce"
  use_constrained_gradient: False
  mellowmax_alpha: 1.0
  early_stop: False
  use_prefix_cache: True
  allow_non_ascii: False
  allow_special: False
  filter_ids: True
  verbosity: WARNING
  token_selection: default
  grow_target: False
  grad_smoothing: 1
  grad_momentum: 0.0
  # REINFORCE-specific parameters
  judge_model_name: "cais/HarmBench-Llama-2-13b-cls"
  judge_weight: 1.0
  target_weight: 0.0
  # Generation parameters
  gen_max_len: 128
  gen_topk: 256
  gen_temperatures: [0.0, 0.7]
  gen_additional_judge_lengths: [20, 40, 80]
  gen_in_parallel_over_temps: False
  # Baseline parameters
  bsln_temperature_complete: 0.0
  bsln_reward_clamp_min: 0.5
  bsln_reward_clamp_max: 1.0
  bsln_ignore: False
  # REINFORCE weighting
  include_most_harmful: True
  include_most_harmful_min_reward_thres: 0.2
  include_most_harmful_likelihood_thres: 0.75
  add_nogen_reward_baseline: 0.1
  token_reinforce_weighting: "token"
  normalize_reinforce_loss: True
  judge_with_control: False
  # Search parameters
  search_target_metric: "agg_reinforce_loss"
  search_monotonically: False
  search_deterministic_loss: True
  search_patience: -1
  search_greedy_reward_exploit_threshold: 0.8
  search_sample_strategy: "gradient"
  selection_extend_length_harmfulness: 0.01
  selection_starting_batch_size: 256
  # Early stopping
  early_stopping_abort: False
  early_stopping_abort_min_loss: 0.1
  early_stopping_key: "agg_reinforce_loss"
  # Token position weighting
  token_position_weighting_kwargs:
    name: "linear"
    first_last_ratio: 5.0
human_jailbreaks:
  name: human_jailbreaks
  type: discrete
  version: 0.0.1
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 1
pair:
  name: pair
  type: discrete
  version: 0.0.1
  seed: ${attacks._default.seed}
  generation_config: ${attacks._default.generation_config}
  num_streams: 1
  keep_last_num: 3
  num_steps: 20
  attack_model:
    id: lmsys/vicuna-13b-v1.5
    tokenizer_id: lmsys/vicuna-13b-v1.5
    dtype: bfloat16
    compile: false
    trust_remote_code: True
    short_name: vicuna
    developer_name: lmsys
    max_attempts: 10
    max_new_tokens: 512
    temperature: 1
    chat_template: vicuna
    top_p: 0.9
  target_model:
    max_new_tokens: 256
    temperature: 0
    top_p: 1
  judge_model:
    id: null
    tokenizer_id: null
    dtype: null
    compile: null
    trust_remote_code: null
    short_name: null
    developer_name: null
    chat_template: null
pgd:
  name: pgd
  type: continuous
  version: 0.0.1
  placement: suffix
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 100
  optim_str_init: "x x x x x x x x x x x x x x x x x x x x" # all tested tokenizers convert this to exactly 20 tokens
  epsilon: 1.
  alpha: 0.001
  embedding_scale: null
  normalize_alpha: true
  normalize_gradient: false
  original_model: null
  tie_logits: 0.0
  tie_features: 0.0
  projection: l2
  loss: ce
  attack_space: embedding
  optimizer: "FGSM"
  optimizer_config:
    weight_decay: 0.0
    betas: [0.9, 0.999]
  random_restart_interval: 40
  random_restart_epsilon: 0.1
  log_embeddings: true
pgd_discrete:
  name: pgd_discrete
  type: hybrid
  version: 0.0.1
  placement: suffix
  num_steps: 100
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  optim_str_init: "x x x x x x x x x x x x x x x x x x x x" # all tested tokenizers convert this to exactly 20 tokens
  optimizer: "Adam"  # "Adam" or "SAM"
  projection: "simplex"  # "simplex", "l2", "l1", or null
  alpha: 0.1
  restart_every: 100
  lr_scheduler:
    type: "sequential"  # "constant", "cosine", or "sequential"
    factor: 1.0
    eta_min: 0.325
    T_0: 60
    total_iters: 100
  initialization: "one_hot"  # "random" or "one_hot"
  entropy_factor: 0.4
  anneal: true
  anneal_config:
    start: 0
    duration: 250
    attrs: ["entropy_factor"]
    mode: "uniform"  # "uniform" or "uniform_log"
    init_entropy_factor: 0.0
    end_entropy_factor: 0.4
  grad_clip_value: 20.0
  grad_clip_strategy: "token_norm"  # "norm", "token_norm", or "value"
  tsallis_q2_proj_config:
    iter: 1
    exclude_already_zero: true
  entropy_factor_scale_by_relaxation_gap: 0.1
  entropy_factor_alternate_scheduler: true
  langevin_dynamics_std: null  # float value to enable, null to disable
prefilling:
  name: prefilling
  type: discrete
  version: 0.0.1
  seed: ${attacks._default.seed}
  num_steps: 1
  batch_size: 300
  generation_config: ${attacks._default.generation_config}
random_search:
  name: random_search
  type: discrete
  version: 0.0.2
  placement: "suffix"
  seed: ${attacks._default.seed}
  num_steps: 100
  neighborhood_radius: 1
  candidates_per_generation: 8
  optim_str_init: "x x x x x x x x x x x x x x x x x x x x" # all tested tokenizers convert this to exactly 20 tokens
  generation_config: ${attacks._default.generation_config}
reinforce:
  name: reinforce
  type: discrete
  version: 0.0.1
  generation_config: ${attacks._default.generation_config}
  seed: ${attacks._default.seed}
  num_steps: 100
  batch_size: 512
  optim_str_init: "x x x x x x x x x x x x x x x x x x x x" # all tested tokenizers convert this to exactly 20 tokens
  search_width: 512
  topk: 256
  n_replace: 1
  buffer_size: 0
  judge_model: strong_reject
  loss: ce
  use_constrained_gradient: False
  mellowmax_alpha: 1.0
  early_stop: False
  use_prefix_cache: True
  allow_non_ascii: False
  allow_special: False
  filter_ids: True
  verbosity: WARNING
  token_selection: default
  grow_target: False
  grad_smoothing: 1
  grad_momentum: 0.0   # 0.5 works quite well
